{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gate Value Calculation \n",
    "\n",
    "$\\alpha(E_i) = \\frac{\\sum_{j=0}^{N} \\exp(h \\cdot e_j)}{\\exp(h \\cdot e_i)}$\n",
    "1. **h** is the hidden representation of the input token. **h** belongs to the space $\\mathbb{R}^d$, where **d** is the dimnesionality of hidden state.\n",
    "2. $e_i$ is the trainable embedding for expert $E_i$, which is also in $\\mathbb{R}^d$.The embedding is typically a learned vector for each expert.\n",
    "3. The tern **h.$e_i$** represents the dot product between the hidden representation **h** and the expert embedding $e_i$, resulting in a scalar value.\n",
    "\n",
    "### Output Calculation\n",
    "\n",
    "$ o= h + \\sum_{i=0}^{N} \\ alpha(E_i)\\cdot E_i(h)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden representation h:  (64,)\n",
      "Trainable embeddings e_i: 3 (64,)\n",
      "Dot products h.e_i:  (3,)\n",
      "Gate values (alpha(E_i)):  (3,)\n",
      "Final output after applying LoRA modules and gate values:  (64,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def softmax(x):\n",
    "    return np.exp(x)/ np.sum(np.exp(x), axis=0)\n",
    "\n",
    "d = 64\n",
    "R = 16\n",
    "num_experts = 3\n",
    "\n",
    "A_matrices = [np.random.rand(d,R) for _  in range(num_experts)]\n",
    "B_matrices = [np.random.rand(R,d) for _ in range(num_experts)]\n",
    "\n",
    "h = np.random.randn(d) # gating value of routing h.\n",
    "\n",
    "trainable_embeddings = [np.random.randn(d) for _ in range(num_experts)]  # e_i for each expert.\n",
    "\n",
    "lora_outputs = [] \n",
    "\n",
    "for i in range(num_experts):\n",
    "    A_i = A_matrices[i]\n",
    "    B_i = B_matrices[i]\n",
    "    \n",
    "    delta_h_i = B_i.T @ (A_i.T @ h) \n",
    "    lora_outputs.append(delta_h_i)\n",
    "    \n",
    "\n",
    "    \n",
    "dot_products = np.array([np.dot(h, e_i) for e_i in trainable_embeddings])\n",
    "gate_values = softmax(dot_products)\n",
    "\n",
    "final_output = np.zeros_like(h)\n",
    "for i in range(num_experts):\n",
    "    final_output += gate_values[i] * lora_outputs[i]\n",
    "    \n",
    "    \n",
    "print(\"Hidden representation h: \", h.shape)\n",
    "print(\"Trainable embeddings e_i:\",len(trainable_embeddings), trainable_embeddings[0].shape)\n",
    "print(\"Dot products h.e_i: \", dot_products.shape)\n",
    "print(\"Gate values (alpha(E_i)): \", gate_values.shape)\n",
    "print(\"Final output after applying LoRA modules and gate values: \", final_output.shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mixture of LoRA Experts (MoLE),\n",
    "MoLE extends the transformer architecture by combining outputs from multiple LoRA modules via a gating function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final output after applying LoRA modules and gating values: (64, 10)\n",
      "[[ 6.63664001e+01  1.21169162e+02  1.19005032e+02 -5.48564765e+01\n",
      "   1.52995656e+02  4.38109495e+00  9.80307783e+01 -3.41103151e+01\n",
      "   1.48912680e+02 -1.00108733e+01]\n",
      " [-4.15256861e+00 -2.43828317e+02  1.44777236e+02  1.62484582e+00\n",
      "  -2.42556224e+01  4.45106700e+01  1.14470025e+02 -1.85887045e+02\n",
      "   1.81165093e+02  3.07562093e+01]\n",
      " [-4.04077237e+00 -5.36999342e+01 -5.36575322e+01 -4.06371245e+01\n",
      "   3.84304986e+01  5.67823824e+01 -1.35863398e+02  1.21899585e+02\n",
      "  -4.07118474e+01  3.80647807e+01]\n",
      " [-7.46804561e+01  8.60298787e+01  1.19382769e+02  1.96895284e+02\n",
      "  -7.55310386e+01  5.77029444e+01 -1.93285081e+02  2.95792889e+01\n",
      "  -9.89373177e+01 -2.45987734e+02]\n",
      " [ 3.56483224e+01 -9.20338770e+01 -1.14513615e+01 -4.01326046e+01\n",
      "   1.46201390e+02  3.14412101e+01  2.92663914e+02 -7.63706103e+01\n",
      "   1.21275866e+02  3.21886581e+01]\n",
      " [-1.14672494e+02  3.55407112e+02 -1.08681656e+02 -4.15055169e+01\n",
      "   8.53496638e+01  1.65108665e+02  4.75444572e+01  4.61315135e+01\n",
      "   2.10087579e+02  1.53781545e+02]\n",
      " [ 2.62462262e+02  3.11349772e+02 -1.06017406e+01 -1.58743466e+01\n",
      "  -1.19456435e+02  1.20815455e+01  7.82373270e+00  1.77944595e+02\n",
      "  -2.57558767e+02  1.09178272e+02]\n",
      " [-1.06943323e+02  3.02040509e+02 -3.09663410e+02 -1.22442759e+01\n",
      "   1.85556064e+01 -3.91206047e+01 -2.80558806e+01  3.08127132e+02\n",
      "  -1.40746915e+02 -1.12167817e+02]\n",
      " [ 3.28846007e+02 -1.13924499e+02  1.30008879e+02  1.01591556e+02\n",
      "   7.67574402e+01  2.25477769e+01 -2.49496975e+01  3.54830758e+01\n",
      "  -1.18043533e+01  3.85892269e+01]\n",
      " [-2.19585770e+00  9.51908703e+01 -1.05098304e+02  5.14043131e+01\n",
      "  -9.17738637e+01 -7.99042522e+01  5.64508521e+01  1.13227577e+02\n",
      "   6.70008413e+01 -1.61260085e+02]\n",
      " [ 2.29211300e+00 -1.81366710e+02  1.84762308e+02 -7.14873919e+01\n",
      "   1.59407678e+02 -2.52383222e+01 -2.14841044e+01 -1.99111204e+02\n",
      "  -9.18327938e+01  1.51469535e+02]\n",
      " [-9.79726320e+01 -5.75947521e+00 -3.82287105e+00  2.92097144e+02\n",
      "  -2.95663276e+01 -3.60297691e-01  1.99425413e+02  5.06768138e+01\n",
      "   1.79259538e+02 -6.81190265e+01]\n",
      " [ 5.73030596e+01 -1.81643640e+02 -1.05566119e+02  6.46315118e+01\n",
      "  -5.79636786e+01  3.80975925e+01  2.96316968e+01  1.11459534e+02\n",
      "   5.65417520e+01 -2.39196276e+01]\n",
      " [ 2.21891056e+01  2.35839664e+02  2.88089940e+01 -5.86534879e+01\n",
      "  -1.39732083e+02  1.34015517e+02 -1.63904031e+02  1.95161383e+02\n",
      "  -2.66409400e+02 -6.10999268e+01]\n",
      " [ 1.30694929e+02 -1.15875500e+02 -1.36017813e+02 -2.19229065e+02\n",
      "   2.55754645e+01 -1.44953684e+02 -6.88749965e+01  2.67937369e+02\n",
      "  -9.27216984e+01  1.96211721e+02]\n",
      " [ 1.46355049e+02  1.95216054e+02  3.45305196e+01 -1.63746452e+02\n",
      "   1.84682240e+02  1.37348958e+02 -5.09428049e+01  7.37896209e+01\n",
      "   1.01999649e+02 -3.44715099e+00]\n",
      " [ 4.20365487e+01  9.10908905e+01 -6.71060497e+01 -5.23540717e+00\n",
      "   2.25774453e+02  1.04968817e+02 -7.29214243e+01 -1.08647498e+02\n",
      "  -1.07336010e+01 -8.21709690e+00]\n",
      " [-1.87277709e+01 -2.75920675e+02 -1.28096435e+01  8.97649355e+01\n",
      "   1.68445636e+02 -2.08961614e+02 -9.70488914e+01 -6.02334826e+01\n",
      "   3.67993821e+00 -7.85596702e+00]\n",
      " [ 5.05462326e+01 -3.87612833e+01 -5.96927710e+01 -2.45425110e+02\n",
      "  -2.85149549e+02 -1.22285023e+02  2.83737344e+01  2.93755468e+02\n",
      "  -2.25887273e+02  2.10432520e+02]\n",
      " [ 1.37903695e+02 -6.18850465e+01 -1.94858435e+02 -8.25098260e+01\n",
      "  -7.39260431e+01 -9.11308106e+01 -1.27508722e+02  1.25683502e+02\n",
      "  -1.23186863e+02 -1.86487142e+02]\n",
      " [ 2.38012661e+02  1.58235952e+02  1.41318038e+02 -9.80658716e+01\n",
      "   3.06880315e+01 -1.20329429e+02  5.07352230e+01  1.04485955e+02\n",
      "   5.12643563e+01  9.20851190e+01]\n",
      " [ 2.02562494e+02 -1.71016095e+00 -1.25111667e+01 -7.27730909e+01\n",
      "  -1.56900494e+02  1.05274990e+02 -9.50289954e+01  1.00183944e+02\n",
      "   9.62364645e+01  3.39192457e+01]\n",
      " [-1.48852673e+02 -1.61517587e+02 -1.17418865e+02 -1.40534413e+02\n",
      "   1.57497744e+02 -1.92651718e+02  1.58841342e+02  1.63618092e+01\n",
      "   4.64012923e+02  1.97506283e+02]\n",
      " [-1.43334497e+02 -3.11077851e+02 -3.11151477e+01  2.13947715e+02\n",
      "  -8.24920664e+00 -2.75727887e+02  7.76754647e+01  7.09335545e+01\n",
      "   7.73843307e+01  1.16024082e+02]\n",
      " [-2.21465505e+02  1.01956768e+02 -6.56574737e+01  3.18282888e+02\n",
      "   5.98315733e+01  1.36415405e+02 -4.23045685e+01 -2.44409028e+02\n",
      "   2.14806029e+01  4.00115525e+01]\n",
      " [ 1.52884598e+02 -1.61755978e+02 -1.11287152e+02  3.17798169e+01\n",
      "   2.69006721e+02 -1.44292721e+02 -1.96654753e+01 -1.68580183e+01\n",
      "   6.56483463e+01  1.16173521e+02]\n",
      " [ 6.04456549e+01  2.49960581e+02 -1.27618129e+02 -2.78647539e+02\n",
      "  -3.54641260e+01  1.79113489e+02 -2.74443558e+01  8.73303220e+01\n",
      "  -6.57223937e+01  2.09273131e+02]\n",
      " [-1.73581037e+02  1.28373133e+02  1.27711393e+01  3.58078904e+01\n",
      "  -2.20182646e+02  1.39549449e+02  2.10739123e+01 -6.09536915e+01\n",
      "   1.05417532e+02 -5.34946062e+01]\n",
      " [ 5.50924417e+01 -1.06103399e+02  4.99396745e+01 -6.83078012e+01\n",
      "   7.53862265e+00 -4.55294477e+01  2.18758441e+02  1.50581292e+02\n",
      "  -1.71708339e+02  2.94357960e+02]\n",
      " [ 8.69587224e+01 -1.05767750e+02  7.64176570e+01  1.86383721e+01\n",
      "   3.82609930e+02  1.08621860e+02 -9.82616933e+01 -4.37690531e+01\n",
      "  -6.90180471e+01 -1.62746794e+00]\n",
      " [-2.33985825e+02  6.51202359e+01 -2.09996968e+02  1.65855276e+02\n",
      "   2.12415444e+02  9.98332901e+01  1.33883370e+02 -3.83546117e+00\n",
      "   2.26826574e+02  1.07082878e+02]\n",
      " [-7.10425466e+01 -3.72136165e+01  1.05870884e+02  2.41980309e+00\n",
      "  -2.60731263e+02 -1.45358374e+02 -1.95205079e+00  7.04070942e+01\n",
      "  -1.60036226e+02 -7.11978631e+01]\n",
      " [ 2.51808462e+02 -7.38281654e+01  3.11514657e+01 -1.38173689e+02\n",
      "   2.11003380e+01 -6.96505413e+01  2.51031312e+01 -5.37658654e+00\n",
      "   3.51160593e+01  4.94694063e+01]\n",
      " [-7.47280236e+01  2.05947236e+02 -1.50681607e+02  3.61762303e+01\n",
      "  -1.61170624e+02  6.70477660e+01 -8.40394897e+01  1.15245881e+02\n",
      "  -1.12660524e+02 -1.03857971e+02]\n",
      " [ 3.39372218e+02 -1.76000485e+02  2.15024157e+02  4.02254667e+01\n",
      "   1.41754425e+02  4.70445950e+01 -2.15212294e+02 -2.95762612e+02\n",
      "   9.43625958e+01 -1.86393766e+02]\n",
      " [-6.71608192e+01  1.85540108e+02  8.97137638e+01  6.26371632e+01\n",
      "   1.74051551e+02  2.12270558e+02 -1.66996540e+02 -2.34512624e+02\n",
      "   6.26831891e+01 -4.00794571e+02]\n",
      " [ 1.85052183e+01  6.34577543e+01  7.08829884e+01 -8.39549634e+01\n",
      "   2.66274222e+02 -2.93472407e+02 -1.93279778e+02  1.10366840e+02\n",
      "  -1.61173177e+02  7.52950419e+01]\n",
      " [-5.81144731e+01 -6.55384746e+01 -2.70614569e+02 -1.11533502e+02\n",
      "  -2.24024438e+02 -2.66987134e+02 -4.51084958e+01  2.86520256e+02\n",
      "   1.26910884e+01 -1.31924279e+01]\n",
      " [-1.75344041e+02 -9.39165128e+01 -2.02820400e+02 -5.95393523e+01\n",
      "  -1.66016843e+02 -5.09675538e+01 -1.59544258e+01  1.69792738e+02\n",
      "  -5.11451290e+01  6.71831156e+01]\n",
      " [ 1.53739928e+02 -1.39630597e+02  1.40622065e+02 -1.17017789e+02\n",
      "   3.98776339e+02 -1.94884950e+02 -1.78434586e+02  2.27418243e+01\n",
      "   1.64473992e+02  1.31619851e+02]\n",
      " [ 1.73179027e+02 -1.20148867e+02  5.09128325e+01 -1.29913630e+02\n",
      "   9.88383904e+01  1.27493392e+01 -5.62605476e+00 -1.08486870e+02\n",
      "  -5.60792434e+01  2.64855882e+01]\n",
      " [ 9.79021741e+01 -1.44789456e+02 -3.06882527e+01 -1.86123087e+01\n",
      "   1.47587162e+02 -4.93174738e+02 -2.15307695e+01  5.91988170e+01\n",
      "  -3.89317168e+01 -6.94155568e+01]\n",
      " [-2.22652103e+02  2.71520853e+02 -1.54608146e+02  9.83810664e+01\n",
      "  -9.30520574e+01 -2.83838144e+01  4.62858726e+01  3.24626729e+02\n",
      "   1.80726640e+02 -3.19386659e+02]\n",
      " [-9.87747172e+01  2.70895969e+02 -1.31515474e+02 -1.39804858e+00\n",
      "   6.89438911e+00  4.15070548e+01 -8.57001557e+01  1.74088226e+02\n",
      "  -7.47659505e+01 -1.57830265e+02]\n",
      " [ 4.52663993e+01 -1.20119538e+02  8.16517584e+01  5.32982166e+00\n",
      "  -1.43792120e+02  1.40019923e+02  6.46588878e+01 -1.71145963e+02\n",
      "   1.51440984e+02 -1.90044263e+02]\n",
      " [ 2.20399323e+02 -3.03134883e+02  1.17757127e+02 -1.61371212e+02\n",
      "   1.44175210e+02 -1.22767114e+01 -3.28187946e+01 -4.22489575e+02\n",
      "   2.28284105e+02  5.74568084e+01]\n",
      " [ 1.49241046e+02  8.60402434e+01  1.66639809e+01 -1.88384760e+01\n",
      "   9.80932101e+01  3.24336664e+01  1.29554133e+02  1.62068625e+02\n",
      "   5.20211154e+01 -1.46701431e+02]\n",
      " [ 9.62644878e+01 -1.80121123e+02  1.80376906e+02  3.14556006e+01\n",
      "   4.96720435e+00 -7.83217841e+01 -4.93555691e+01 -8.89595823e+01\n",
      "   2.52436234e+01  1.04029307e+01]\n",
      " [-1.58537433e+02 -1.35831444e+02  2.70390094e+01 -9.62769241e+01\n",
      "   1.77778199e+02 -2.84669769e+01  1.96533045e+02  2.44914059e+02\n",
      "   2.62640148e+02  1.57366894e+02]\n",
      " [-5.14305715e+01  1.93800278e+01  1.78875307e+02  3.77948697e+02\n",
      "   4.01604362e+02 -6.60468039e+01 -9.69768044e+01 -2.32341230e+02\n",
      "   4.77327485e+01 -3.08311542e+01]\n",
      " [ 2.01579370e+02 -1.05574698e+02  1.16601149e+02  2.30924577e+02\n",
      "  -1.30790596e+02  2.21356396e+02  1.95350419e+02 -3.82609139e+02\n",
      "   7.06677279e+01 -1.34280780e+02]\n",
      " [-2.48987119e+02  1.52023936e+02 -3.72523522e+02 -1.61851435e+02\n",
      "   9.62734780e+01  1.49357809e+02 -1.37263442e+02  2.84025088e+02\n",
      "   8.09526304e+01  1.38683606e+02]\n",
      " [-3.26902902e+02  1.05184005e+01  1.39138483e+02  3.11595296e+02\n",
      "  -3.00595900e+02  1.07812623e+02 -1.05731369e+02 -1.59982646e+02\n",
      "  -1.32128085e+02 -1.89896432e+02]\n",
      " [-6.51486283e+01  2.70645965e+01 -1.08682050e+02 -4.25548212e+01\n",
      "   1.02298424e+02 -2.89373114e+01  1.39653025e+01  7.57717761e+01\n",
      "   4.77860246e+01  1.79045190e+02]\n",
      " [ 2.45131803e+02 -9.92547453e+00  2.09258833e+01  1.89272276e+01\n",
      "   2.53310712e+02 -4.01852071e+02 -2.60527368e+01 -1.50698723e+02\n",
      "  -1.07413093e+02 -2.03031451e+01]\n",
      " [-5.00994644e+01 -1.55537227e+00 -2.28323637e+02 -6.87597952e+01\n",
      "  -2.03682326e+02 -1.74906468e+02  1.07006471e+02  1.53553118e+02\n",
      "   6.09182344e+01 -6.62489291e+01]\n",
      " [-1.00915624e+02 -1.19621004e+02 -7.13376047e+00 -1.81899066e+02\n",
      "   4.49470568e+01  4.62717699e+01 -2.10229976e+02 -7.96311717e+01\n",
      "   7.88969020e+01  5.06005204e+01]\n",
      " [ 4.91846275e+01  5.34500902e+01 -5.66418209e+00  2.08042352e+01\n",
      "  -1.07421985e+02 -2.78523128e+02 -1.46373686e+02 -1.92651921e+02\n",
      "  -9.73136677e+01 -5.01278733e+01]\n",
      " [-1.83679731e+01  1.21422688e+02  7.64683370e+01  5.28916216e+01\n",
      "  -2.48569070e+02  1.33699295e+02 -1.18436888e+02 -1.36072271e+02\n",
      "  -3.88960918e-01 -1.69407154e+01]\n",
      " [ 5.19020944e+01 -1.48137464e+02  2.30617864e+02  1.90292614e+02\n",
      "   1.94413819e+02 -1.46357793e+02  5.98414024e+01 -3.99264134e+02\n",
      "   2.25877465e+01 -6.04299840e+01]\n",
      " [ 3.24442989e+02  2.97713901e+01 -7.14541634e+01 -1.68320527e+02\n",
      "   4.64639439e+00 -3.35797913e+01  2.16576828e+02  2.17963505e+02\n",
      "   1.19791528e+02 -6.71558534e+01]\n",
      " [ 1.17177715e+02 -1.84561349e+02  4.49051335e+01  7.16414009e+01\n",
      "  -1.04269480e+02 -5.93434893e+01 -2.93559225e+01 -4.41117658e+01\n",
      "   6.24592894e+01 -4.92626143e+01]\n",
      " [ 1.45377913e+02 -2.26655760e+01  5.60773313e+01  1.34297126e+02\n",
      "   1.56702210e+02  2.76418875e+01 -1.07493979e+02 -2.00773020e+02\n",
      "  -2.71171565e+02  2.45001720e+01]\n",
      " [-1.82642509e+02 -1.82472066e+02 -5.32771751e+00  1.42005434e+02\n",
      "   2.29670733e+01 -2.90994552e+02 -1.01125805e+01  1.04074311e+02\n",
      "   3.00246099e+01 -1.39392905e+02]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def softmax(x, temperature=1.0):\n",
    "    scaled_x = x / temperature\n",
    "    return np.exp(scaled_x) / np.sum(np.exp(scaled_x), axis=0)\n",
    "\n",
    "\n",
    "d = 64  \n",
    "R = 16  \n",
    "num_experts = 3  \n",
    "L = 10  \n",
    "\n",
    "pretrained_params = np.random.randn(d, d)\n",
    "\n",
    "\n",
    "A_matrices = [np.random.randn(d, R) for _ in range(num_experts)]  \n",
    "B_matrices = [np.random.randn(R, d) for _ in range(num_experts)]\n",
    "\n",
    "trainable_embeddings = [np.random.randn(d) for _ in range(num_experts)]\n",
    "\n",
    "\n",
    "x = np.random.randn(L, d)\n",
    "def transformer_block(x, pretrained_params):\n",
    "    \n",
    "    # x_prime = x + np.dot(np.dot(np.linalg.inv(pretrained_params), x.T).T, pretrained_params)\n",
    "    # add some attention\n",
    "    x_prime = x + np.dot(pretrained_params, x.T).T\n",
    "    return x_prime\n",
    "\n",
    "\n",
    "F_theta_x = transformer_block(x, pretrained_params)\n",
    "\n",
    "lora_outputs = []\n",
    "for i in range(num_experts):\n",
    "    A_i = A_matrices[i]\n",
    "    B_i = B_matrices[i]\n",
    "\n",
    "    delta_h_i = np.dot(B_i.T, np.dot(A_i.T, F_theta_x.T))\n",
    "    lora_outputs.append(delta_h_i)\n",
    "    \n",
    "E_omega_x_normalize = (F_theta_x - np.mean(F_theta_x,axis=0))/np.std(F_theta_x,axis=0)\n",
    "E_flatten = np.mean( E_omega_x_normalize,axis=0)\n",
    "gating_logits = np.array([np.dot(E_flatten, e_i) for e_i in trainable_embeddings])\n",
    "\n",
    "gating_values = softmax(gating_logits, temperature=1.0)\n",
    "final_output = np.zeros_like(F_theta_x).T\n",
    "for i in range(num_experts):\n",
    "    final_output += gating_values[i] * lora_outputs[i]\n",
    "\n",
    "print(\"Final output after applying LoRA modules and gating values:\", final_output.shape)\n",
    "print(final_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "a1_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
