{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "/home/rajeshupadhayaya/miniconda3/envs/seismic/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "base_model = T5ForConditionalGeneration.from_pretrained('google/c-t5-base')\n",
    "tokenizer = T5Tokenizer.from_pretrained('google/flan-t5-base')\n",
    "\n",
    "input_text = \"The quick brown fox jumps over the lazy dog.\"\n",
    "inputs = tokenizer(input_text, return_tensors='pt')\n",
    "\n",
    "input_ids = inputs['input_ids']\n",
    "attention_mask = inputs['attention_mask']\n",
    "\n",
    "embedding_output = base_model.encoder.embed_tokens(input_ids)\n",
    "\n",
    "encoder_layer = base_model.encoder.block[0]\n",
    "attention_Layer = encoder_layer.layer[0]\n",
    "ff_layer = encoder_layer.layer[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./lora_trained/lora-t5-squad were not used when initializing T5ForConditionalGeneration: ['decoder.block.0.layer.0.SelfAttention.q.base_layer.weight', 'decoder.block.0.layer.0.SelfAttention.q.lora_A.default.weight', 'decoder.block.0.layer.0.SelfAttention.q.lora_B.default.weight', 'decoder.block.0.layer.0.SelfAttention.v.base_layer.weight', 'decoder.block.0.layer.0.SelfAttention.v.lora_A.default.weight', 'decoder.block.0.layer.0.SelfAttention.v.lora_B.default.weight', 'decoder.block.0.layer.1.EncDecAttention.q.base_layer.weight', 'decoder.block.0.layer.1.EncDecAttention.q.lora_A.default.weight', 'decoder.block.0.layer.1.EncDecAttention.q.lora_B.default.weight', 'decoder.block.0.layer.1.EncDecAttention.v.base_layer.weight', 'decoder.block.0.layer.1.EncDecAttention.v.lora_A.default.weight', 'decoder.block.0.layer.1.EncDecAttention.v.lora_B.default.weight', 'decoder.block.1.layer.0.SelfAttention.q.base_layer.weight', 'decoder.block.1.layer.0.SelfAttention.q.lora_A.default.weight', 'decoder.block.1.layer.0.SelfAttention.q.lora_B.default.weight', 'decoder.block.1.layer.0.SelfAttention.v.base_layer.weight', 'decoder.block.1.layer.0.SelfAttention.v.lora_A.default.weight', 'decoder.block.1.layer.0.SelfAttention.v.lora_B.default.weight', 'decoder.block.1.layer.1.EncDecAttention.q.base_layer.weight', 'decoder.block.1.layer.1.EncDecAttention.q.lora_A.default.weight', 'decoder.block.1.layer.1.EncDecAttention.q.lora_B.default.weight', 'decoder.block.1.layer.1.EncDecAttention.v.base_layer.weight', 'decoder.block.1.layer.1.EncDecAttention.v.lora_A.default.weight', 'decoder.block.1.layer.1.EncDecAttention.v.lora_B.default.weight', 'decoder.block.10.layer.0.SelfAttention.q.base_layer.weight', 'decoder.block.10.layer.0.SelfAttention.q.lora_A.default.weight', 'decoder.block.10.layer.0.SelfAttention.q.lora_B.default.weight', 'decoder.block.10.layer.0.SelfAttention.v.base_layer.weight', 'decoder.block.10.layer.0.SelfAttention.v.lora_A.default.weight', 'decoder.block.10.layer.0.SelfAttention.v.lora_B.default.weight', 'decoder.block.10.layer.1.EncDecAttention.q.base_layer.weight', 'decoder.block.10.layer.1.EncDecAttention.q.lora_A.default.weight', 'decoder.block.10.layer.1.EncDecAttention.q.lora_B.default.weight', 'decoder.block.10.layer.1.EncDecAttention.v.base_layer.weight', 'decoder.block.10.layer.1.EncDecAttention.v.lora_A.default.weight', 'decoder.block.10.layer.1.EncDecAttention.v.lora_B.default.weight', 'decoder.block.11.layer.0.SelfAttention.q.base_layer.weight', 'decoder.block.11.layer.0.SelfAttention.q.lora_A.default.weight', 'decoder.block.11.layer.0.SelfAttention.q.lora_B.default.weight', 'decoder.block.11.layer.0.SelfAttention.v.base_layer.weight', 'decoder.block.11.layer.0.SelfAttention.v.lora_A.default.weight', 'decoder.block.11.layer.0.SelfAttention.v.lora_B.default.weight', 'decoder.block.11.layer.1.EncDecAttention.q.base_layer.weight', 'decoder.block.11.layer.1.EncDecAttention.q.lora_A.default.weight', 'decoder.block.11.layer.1.EncDecAttention.q.lora_B.default.weight', 'decoder.block.11.layer.1.EncDecAttention.v.base_layer.weight', 'decoder.block.11.layer.1.EncDecAttention.v.lora_A.default.weight', 'decoder.block.11.layer.1.EncDecAttention.v.lora_B.default.weight', 'decoder.block.2.layer.0.SelfAttention.q.base_layer.weight', 'decoder.block.2.layer.0.SelfAttention.q.lora_A.default.weight', 'decoder.block.2.layer.0.SelfAttention.q.lora_B.default.weight', 'decoder.block.2.layer.0.SelfAttention.v.base_layer.weight', 'decoder.block.2.layer.0.SelfAttention.v.lora_A.default.weight', 'decoder.block.2.layer.0.SelfAttention.v.lora_B.default.weight', 'decoder.block.2.layer.1.EncDecAttention.q.base_layer.weight', 'decoder.block.2.layer.1.EncDecAttention.q.lora_A.default.weight', 'decoder.block.2.layer.1.EncDecAttention.q.lora_B.default.weight', 'decoder.block.2.layer.1.EncDecAttention.v.base_layer.weight', 'decoder.block.2.layer.1.EncDecAttention.v.lora_A.default.weight', 'decoder.block.2.layer.1.EncDecAttention.v.lora_B.default.weight', 'decoder.block.3.layer.0.SelfAttention.q.base_layer.weight', 'decoder.block.3.layer.0.SelfAttention.q.lora_A.default.weight', 'decoder.block.3.layer.0.SelfAttention.q.lora_B.default.weight', 'decoder.block.3.layer.0.SelfAttention.v.base_layer.weight', 'decoder.block.3.layer.0.SelfAttention.v.lora_A.default.weight', 'decoder.block.3.layer.0.SelfAttention.v.lora_B.default.weight', 'decoder.block.3.layer.1.EncDecAttention.q.base_layer.weight', 'decoder.block.3.layer.1.EncDecAttention.q.lora_A.default.weight', 'decoder.block.3.layer.1.EncDecAttention.q.lora_B.default.weight', 'decoder.block.3.layer.1.EncDecAttention.v.base_layer.weight', 'decoder.block.3.layer.1.EncDecAttention.v.lora_A.default.weight', 'decoder.block.3.layer.1.EncDecAttention.v.lora_B.default.weight', 'decoder.block.4.layer.0.SelfAttention.q.base_layer.weight', 'decoder.block.4.layer.0.SelfAttention.q.lora_A.default.weight', 'decoder.block.4.layer.0.SelfAttention.q.lora_B.default.weight', 'decoder.block.4.layer.0.SelfAttention.v.base_layer.weight', 'decoder.block.4.layer.0.SelfAttention.v.lora_A.default.weight', 'decoder.block.4.layer.0.SelfAttention.v.lora_B.default.weight', 'decoder.block.4.layer.1.EncDecAttention.q.base_layer.weight', 'decoder.block.4.layer.1.EncDecAttention.q.lora_A.default.weight', 'decoder.block.4.layer.1.EncDecAttention.q.lora_B.default.weight', 'decoder.block.4.layer.1.EncDecAttention.v.base_layer.weight', 'decoder.block.4.layer.1.EncDecAttention.v.lora_A.default.weight', 'decoder.block.4.layer.1.EncDecAttention.v.lora_B.default.weight', 'decoder.block.5.layer.0.SelfAttention.q.base_layer.weight', 'decoder.block.5.layer.0.SelfAttention.q.lora_A.default.weight', 'decoder.block.5.layer.0.SelfAttention.q.lora_B.default.weight', 'decoder.block.5.layer.0.SelfAttention.v.base_layer.weight', 'decoder.block.5.layer.0.SelfAttention.v.lora_A.default.weight', 'decoder.block.5.layer.0.SelfAttention.v.lora_B.default.weight', 'decoder.block.5.layer.1.EncDecAttention.q.base_layer.weight', 'decoder.block.5.layer.1.EncDecAttention.q.lora_A.default.weight', 'decoder.block.5.layer.1.EncDecAttention.q.lora_B.default.weight', 'decoder.block.5.layer.1.EncDecAttention.v.base_layer.weight', 'decoder.block.5.layer.1.EncDecAttention.v.lora_A.default.weight', 'decoder.block.5.layer.1.EncDecAttention.v.lora_B.default.weight', 'decoder.block.6.layer.0.SelfAttention.q.base_layer.weight', 'decoder.block.6.layer.0.SelfAttention.q.lora_A.default.weight', 'decoder.block.6.layer.0.SelfAttention.q.lora_B.default.weight', 'decoder.block.6.layer.0.SelfAttention.v.base_layer.weight', 'decoder.block.6.layer.0.SelfAttention.v.lora_A.default.weight', 'decoder.block.6.layer.0.SelfAttention.v.lora_B.default.weight', 'decoder.block.6.layer.1.EncDecAttention.q.base_layer.weight', 'decoder.block.6.layer.1.EncDecAttention.q.lora_A.default.weight', 'decoder.block.6.layer.1.EncDecAttention.q.lora_B.default.weight', 'decoder.block.6.layer.1.EncDecAttention.v.base_layer.weight', 'decoder.block.6.layer.1.EncDecAttention.v.lora_A.default.weight', 'decoder.block.6.layer.1.EncDecAttention.v.lora_B.default.weight', 'decoder.block.7.layer.0.SelfAttention.q.base_layer.weight', 'decoder.block.7.layer.0.SelfAttention.q.lora_A.default.weight', 'decoder.block.7.layer.0.SelfAttention.q.lora_B.default.weight', 'decoder.block.7.layer.0.SelfAttention.v.base_layer.weight', 'decoder.block.7.layer.0.SelfAttention.v.lora_A.default.weight', 'decoder.block.7.layer.0.SelfAttention.v.lora_B.default.weight', 'decoder.block.7.layer.1.EncDecAttention.q.base_layer.weight', 'decoder.block.7.layer.1.EncDecAttention.q.lora_A.default.weight', 'decoder.block.7.layer.1.EncDecAttention.q.lora_B.default.weight', 'decoder.block.7.layer.1.EncDecAttention.v.base_layer.weight', 'decoder.block.7.layer.1.EncDecAttention.v.lora_A.default.weight', 'decoder.block.7.layer.1.EncDecAttention.v.lora_B.default.weight', 'decoder.block.8.layer.0.SelfAttention.q.base_layer.weight', 'decoder.block.8.layer.0.SelfAttention.q.lora_A.default.weight', 'decoder.block.8.layer.0.SelfAttention.q.lora_B.default.weight', 'decoder.block.8.layer.0.SelfAttention.v.base_layer.weight', 'decoder.block.8.layer.0.SelfAttention.v.lora_A.default.weight', 'decoder.block.8.layer.0.SelfAttention.v.lora_B.default.weight', 'decoder.block.8.layer.1.EncDecAttention.q.base_layer.weight', 'decoder.block.8.layer.1.EncDecAttention.q.lora_A.default.weight', 'decoder.block.8.layer.1.EncDecAttention.q.lora_B.default.weight', 'decoder.block.8.layer.1.EncDecAttention.v.base_layer.weight', 'decoder.block.8.layer.1.EncDecAttention.v.lora_A.default.weight', 'decoder.block.8.layer.1.EncDecAttention.v.lora_B.default.weight', 'decoder.block.9.layer.0.SelfAttention.q.base_layer.weight', 'decoder.block.9.layer.0.SelfAttention.q.lora_A.default.weight', 'decoder.block.9.layer.0.SelfAttention.q.lora_B.default.weight', 'decoder.block.9.layer.0.SelfAttention.v.base_layer.weight', 'decoder.block.9.layer.0.SelfAttention.v.lora_A.default.weight', 'decoder.block.9.layer.0.SelfAttention.v.lora_B.default.weight', 'decoder.block.9.layer.1.EncDecAttention.q.base_layer.weight', 'decoder.block.9.layer.1.EncDecAttention.q.lora_A.default.weight', 'decoder.block.9.layer.1.EncDecAttention.q.lora_B.default.weight', 'decoder.block.9.layer.1.EncDecAttention.v.base_layer.weight', 'decoder.block.9.layer.1.EncDecAttention.v.lora_A.default.weight', 'decoder.block.9.layer.1.EncDecAttention.v.lora_B.default.weight', 'encoder.block.0.layer.0.SelfAttention.q.base_layer.weight', 'encoder.block.0.layer.0.SelfAttention.q.lora_A.default.weight', 'encoder.block.0.layer.0.SelfAttention.q.lora_B.default.weight', 'encoder.block.0.layer.0.SelfAttention.v.base_layer.weight', 'encoder.block.0.layer.0.SelfAttention.v.lora_A.default.weight', 'encoder.block.0.layer.0.SelfAttention.v.lora_B.default.weight', 'encoder.block.1.layer.0.SelfAttention.q.base_layer.weight', 'encoder.block.1.layer.0.SelfAttention.q.lora_A.default.weight', 'encoder.block.1.layer.0.SelfAttention.q.lora_B.default.weight', 'encoder.block.1.layer.0.SelfAttention.v.base_layer.weight', 'encoder.block.1.layer.0.SelfAttention.v.lora_A.default.weight', 'encoder.block.1.layer.0.SelfAttention.v.lora_B.default.weight', 'encoder.block.10.layer.0.SelfAttention.q.base_layer.weight', 'encoder.block.10.layer.0.SelfAttention.q.lora_A.default.weight', 'encoder.block.10.layer.0.SelfAttention.q.lora_B.default.weight', 'encoder.block.10.layer.0.SelfAttention.v.base_layer.weight', 'encoder.block.10.layer.0.SelfAttention.v.lora_A.default.weight', 'encoder.block.10.layer.0.SelfAttention.v.lora_B.default.weight', 'encoder.block.11.layer.0.SelfAttention.q.base_layer.weight', 'encoder.block.11.layer.0.SelfAttention.q.lora_A.default.weight', 'encoder.block.11.layer.0.SelfAttention.q.lora_B.default.weight', 'encoder.block.11.layer.0.SelfAttention.v.base_layer.weight', 'encoder.block.11.layer.0.SelfAttention.v.lora_A.default.weight', 'encoder.block.11.layer.0.SelfAttention.v.lora_B.default.weight', 'encoder.block.2.layer.0.SelfAttention.q.base_layer.weight', 'encoder.block.2.layer.0.SelfAttention.q.lora_A.default.weight', 'encoder.block.2.layer.0.SelfAttention.q.lora_B.default.weight', 'encoder.block.2.layer.0.SelfAttention.v.base_layer.weight', 'encoder.block.2.layer.0.SelfAttention.v.lora_A.default.weight', 'encoder.block.2.layer.0.SelfAttention.v.lora_B.default.weight', 'encoder.block.3.layer.0.SelfAttention.q.base_layer.weight', 'encoder.block.3.layer.0.SelfAttention.q.lora_A.default.weight', 'encoder.block.3.layer.0.SelfAttention.q.lora_B.default.weight', 'encoder.block.3.layer.0.SelfAttention.v.base_layer.weight', 'encoder.block.3.layer.0.SelfAttention.v.lora_A.default.weight', 'encoder.block.3.layer.0.SelfAttention.v.lora_B.default.weight', 'encoder.block.4.layer.0.SelfAttention.q.base_layer.weight', 'encoder.block.4.layer.0.SelfAttention.q.lora_A.default.weight', 'encoder.block.4.layer.0.SelfAttention.q.lora_B.default.weight', 'encoder.block.4.layer.0.SelfAttention.v.base_layer.weight', 'encoder.block.4.layer.0.SelfAttention.v.lora_A.default.weight', 'encoder.block.4.layer.0.SelfAttention.v.lora_B.default.weight', 'encoder.block.5.layer.0.SelfAttention.q.base_layer.weight', 'encoder.block.5.layer.0.SelfAttention.q.lora_A.default.weight', 'encoder.block.5.layer.0.SelfAttention.q.lora_B.default.weight', 'encoder.block.5.layer.0.SelfAttention.v.base_layer.weight', 'encoder.block.5.layer.0.SelfAttention.v.lora_A.default.weight', 'encoder.block.5.layer.0.SelfAttention.v.lora_B.default.weight', 'encoder.block.6.layer.0.SelfAttention.q.base_layer.weight', 'encoder.block.6.layer.0.SelfAttention.q.lora_A.default.weight', 'encoder.block.6.layer.0.SelfAttention.q.lora_B.default.weight', 'encoder.block.6.layer.0.SelfAttention.v.base_layer.weight', 'encoder.block.6.layer.0.SelfAttention.v.lora_A.default.weight', 'encoder.block.6.layer.0.SelfAttention.v.lora_B.default.weight', 'encoder.block.7.layer.0.SelfAttention.q.base_layer.weight', 'encoder.block.7.layer.0.SelfAttention.q.lora_A.default.weight', 'encoder.block.7.layer.0.SelfAttention.q.lora_B.default.weight', 'encoder.block.7.layer.0.SelfAttention.v.base_layer.weight', 'encoder.block.7.layer.0.SelfAttention.v.lora_A.default.weight', 'encoder.block.7.layer.0.SelfAttention.v.lora_B.default.weight', 'encoder.block.8.layer.0.SelfAttention.q.base_layer.weight', 'encoder.block.8.layer.0.SelfAttention.q.lora_A.default.weight', 'encoder.block.8.layer.0.SelfAttention.q.lora_B.default.weight', 'encoder.block.8.layer.0.SelfAttention.v.base_layer.weight', 'encoder.block.8.layer.0.SelfAttention.v.lora_A.default.weight', 'encoder.block.8.layer.0.SelfAttention.v.lora_B.default.weight', 'encoder.block.9.layer.0.SelfAttention.q.base_layer.weight', 'encoder.block.9.layer.0.SelfAttention.q.lora_A.default.weight', 'encoder.block.9.layer.0.SelfAttention.q.lora_B.default.weight', 'encoder.block.9.layer.0.SelfAttention.v.base_layer.weight', 'encoder.block.9.layer.0.SelfAttention.v.lora_A.default.weight', 'encoder.block.9.layer.0.SelfAttention.v.lora_B.default.weight']\n",
      "- This IS expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of T5ForConditionalGeneration were not initialized from the model checkpoint at ./lora_trained/lora-t5-squad and are newly initialized: ['decoder.block.0.layer.0.SelfAttention.q.weight', 'decoder.block.0.layer.0.SelfAttention.v.weight', 'decoder.block.0.layer.1.EncDecAttention.q.weight', 'decoder.block.0.layer.1.EncDecAttention.v.weight', 'decoder.block.1.layer.0.SelfAttention.q.weight', 'decoder.block.1.layer.0.SelfAttention.v.weight', 'decoder.block.1.layer.1.EncDecAttention.q.weight', 'decoder.block.1.layer.1.EncDecAttention.v.weight', 'decoder.block.10.layer.0.SelfAttention.q.weight', 'decoder.block.10.layer.0.SelfAttention.v.weight', 'decoder.block.10.layer.1.EncDecAttention.q.weight', 'decoder.block.10.layer.1.EncDecAttention.v.weight', 'decoder.block.11.layer.0.SelfAttention.q.weight', 'decoder.block.11.layer.0.SelfAttention.v.weight', 'decoder.block.11.layer.1.EncDecAttention.q.weight', 'decoder.block.11.layer.1.EncDecAttention.v.weight', 'decoder.block.2.layer.0.SelfAttention.q.weight', 'decoder.block.2.layer.0.SelfAttention.v.weight', 'decoder.block.2.layer.1.EncDecAttention.q.weight', 'decoder.block.2.layer.1.EncDecAttention.v.weight', 'decoder.block.3.layer.0.SelfAttention.q.weight', 'decoder.block.3.layer.0.SelfAttention.v.weight', 'decoder.block.3.layer.1.EncDecAttention.q.weight', 'decoder.block.3.layer.1.EncDecAttention.v.weight', 'decoder.block.4.layer.0.SelfAttention.q.weight', 'decoder.block.4.layer.0.SelfAttention.v.weight', 'decoder.block.4.layer.1.EncDecAttention.q.weight', 'decoder.block.4.layer.1.EncDecAttention.v.weight', 'decoder.block.5.layer.0.SelfAttention.q.weight', 'decoder.block.5.layer.0.SelfAttention.v.weight', 'decoder.block.5.layer.1.EncDecAttention.q.weight', 'decoder.block.5.layer.1.EncDecAttention.v.weight', 'decoder.block.6.layer.0.SelfAttention.q.weight', 'decoder.block.6.layer.0.SelfAttention.v.weight', 'decoder.block.6.layer.1.EncDecAttention.q.weight', 'decoder.block.6.layer.1.EncDecAttention.v.weight', 'decoder.block.7.layer.0.SelfAttention.q.weight', 'decoder.block.7.layer.0.SelfAttention.v.weight', 'decoder.block.7.layer.1.EncDecAttention.q.weight', 'decoder.block.7.layer.1.EncDecAttention.v.weight', 'decoder.block.8.layer.0.SelfAttention.q.weight', 'decoder.block.8.layer.0.SelfAttention.v.weight', 'decoder.block.8.layer.1.EncDecAttention.q.weight', 'decoder.block.8.layer.1.EncDecAttention.v.weight', 'decoder.block.9.layer.0.SelfAttention.q.weight', 'decoder.block.9.layer.0.SelfAttention.v.weight', 'decoder.block.9.layer.1.EncDecAttention.q.weight', 'decoder.block.9.layer.1.EncDecAttention.v.weight', 'encoder.block.0.layer.0.SelfAttention.q.weight', 'encoder.block.0.layer.0.SelfAttention.v.weight', 'encoder.block.1.layer.0.SelfAttention.q.weight', 'encoder.block.1.layer.0.SelfAttention.v.weight', 'encoder.block.10.layer.0.SelfAttention.q.weight', 'encoder.block.10.layer.0.SelfAttention.v.weight', 'encoder.block.11.layer.0.SelfAttention.q.weight', 'encoder.block.11.layer.0.SelfAttention.v.weight', 'encoder.block.2.layer.0.SelfAttention.q.weight', 'encoder.block.2.layer.0.SelfAttention.v.weight', 'encoder.block.3.layer.0.SelfAttention.q.weight', 'encoder.block.3.layer.0.SelfAttention.v.weight', 'encoder.block.4.layer.0.SelfAttention.q.weight', 'encoder.block.4.layer.0.SelfAttention.v.weight', 'encoder.block.5.layer.0.SelfAttention.q.weight', 'encoder.block.5.layer.0.SelfAttention.v.weight', 'encoder.block.6.layer.0.SelfAttention.q.weight', 'encoder.block.6.layer.0.SelfAttention.v.weight', 'encoder.block.7.layer.0.SelfAttention.q.weight', 'encoder.block.7.layer.0.SelfAttention.v.weight', 'encoder.block.8.layer.0.SelfAttention.q.weight', 'encoder.block.8.layer.0.SelfAttention.v.weight', 'encoder.block.9.layer.0.SelfAttention.q.weight', 'encoder.block.9.layer.0.SelfAttention.v.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "input_text = \"The quick brown fox jumps over the lazy dog.\"\n",
    "inputs = tokenizer(input_text, return_tensors='pt')\n",
    "\n",
    "data_name = {'rte', 'mnli', 'squad'}\n",
    "lora_layers = {'attention_Layer':[], 'ff_layer': []}\n",
    "for d in data_name:\n",
    "    lora_path = f\"./lora_trained/lora-t5-{d}\"\n",
    "    lora_base_model = T5ForConditionalGeneration.from_pretrained(lora_path)\n",
    "    lora_encoder_layer = lora_base_model.encoder.block[0]\n",
    "    lora_layers['attention_Layer'] += [lora_encoder_layer.layer[0]]\n",
    "    lora_layers['ff_layer'] += [lora_encoder_layer.layer[1]]\n",
    "# print(lora_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final output shape: torch.Size([13, 768])\n",
      "tensor([[-21.4644,  11.3576,   0.7138,  ...,  -4.5001, -16.1802, -23.4917],\n",
      "        [ -9.5499,  10.4079,   5.3058,  ...,  10.5751,   9.5109, -18.7083],\n",
      "        [ 12.4027,   6.2433,  35.0161,  ...,  22.5951, -30.5896,  40.4467],\n",
      "        ...,\n",
      "        [-29.0437,  34.4034, -21.8787,  ...,  36.0988,  21.4280,  -5.9321],\n",
      "        [  6.0815,   6.6027,  -0.5446,  ...,   3.2604,  11.2176,  -2.8747],\n",
      "        [133.7380,  78.3760,  54.8937,  ...,  43.1555, -59.7224,  93.7194]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "d = 768\n",
    "R = 8\n",
    "N = len(data_name)\n",
    "L = inputs['input_ids'].shape[1]\n",
    "\n",
    "e = nn.Parameter(torch.randn(N *L * d, N))\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    attention_output = attention_Layer(embedding_output,attention_mask)[0]   # Equation 5 of the paper.\n",
    "    feed_forward_output =  ff_layer(attention_output)[0]       # Equation 6 of paper\n",
    "\n",
    "\n",
    "F_theta_x =   feed_forward_output\n",
    "\n",
    "# Apply LoRA experts\n",
    "lora_outputs = torch.zeros((N,L,d))\n",
    "for i in range(N):\n",
    "    lora_attention_output = lora_layers['attention_Layer'][i](embedding_output, attention_mask)[0]    # equation 7 of paper\n",
    "    lora_ff_output = lora_layers['ff_layer'][i](lora_attention_output)[0]   # equation 8 of paper\n",
    "    lora_attention_output = torch.squeeze(lora_attention_output)\n",
    "    \n",
    "    layer_norm = nn.LayerNorm(lora_attention_output.shape)\n",
    "\n",
    "    E_omega_x_normalize = layer_norm(lora_ff_output * lora_attention_output )  # equation 9 of paper.\n",
    "    lora_outputs[i]= E_omega_x_normalize\n",
    "\n",
    "\n",
    "E_omega_x_flattened = lora_outputs.flatten()\n",
    "epsilon = torch.matmul(E_omega_x_flattened, e)    # equation 10 of paper\n",
    "\n",
    "# Softmax to compute gating  meaning gate value of each lora\n",
    "#  learnable parameter of temperature \n",
    "temperature = 1.0 \n",
    "gated_value = F.softmax(epsilon / temperature, dim=0) # equation 11 of paper\n",
    "\n",
    "final_output_E_Omega_x = [ gated_value[x] * lora_outputs[x] for x in range(lora_outputs.shape[0])] # equation 12 of paper\n",
    "\n",
    "\n",
    "# Combine the LoRA outputs based on gating values\n",
    "# slightly confuse on this part.\n",
    "final_output = torch.zeros((L,d))\n",
    "for i in range(N):\n",
    "    final_output += final_output_E_Omega_x[i] + F_theta_x # equation 13 of paper\n",
    "\n",
    "\n",
    "print(\"Final output shape:\", final_output.shape)\n",
    "print(final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seismic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
