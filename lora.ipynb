{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-17T22:13:17.109197500Z",
     "start_time": "2024-08-17T22:13:15.509682Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\incognito\\AppData\\Local\\Temp\\ipykernel_6616\\4239347839.py:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(path))\n"
     ]
    }
   ],
   "source": [
    "# Loading the model\n",
    "class FeedForwardNetwork(torch.nn.Module):\n",
    "    def __init__(self, in_dim, embedding_dim=128, out_dim=10):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(in_dim, embedding_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(embedding_dim, out_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x)\n",
    "        return self.linear(x)\n",
    "    \n",
    "model = FeedForwardNetwork(in_dim=784, out_dim=10, embedding_dim=128)\n",
    "path = \"./model/two_layer_linear_model.pth\"\n",
    "model.load_state_dict(torch.load(path))\n",
    "(w1,b1,w2,b2) = model.parameters()\n",
    "\n",
    "# Freezing weight\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-17T22:13:17.124524600Z",
     "start_time": "2024-08-17T22:13:17.110197500Z"
    }
   },
   "id": "43b5afcfad827a25",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load  the MNIST dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "full_data = datasets.MNIST(root='./data', transform=transform, download=True)\n",
    "split_percent = int(0.25 * len(full_data))\n",
    "train_data1, test_data1, train_data2, test_data2 = random_split(full_data, [split_percent, split_percent, split_percent,\n",
    "                                                                            split_percent])\n",
    "train_data2 = DataLoader(dataset=train_data2, shuffle=True)\n",
    "test_loader2 = DataLoader(dataset=test_data2, shuffle=True)\n",
    "in_dim = (train_data2.dataset[0][0].size()[1]) ** 2\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-17T22:13:17.158692900Z",
     "start_time": "2024-08-17T22:13:17.124524600Z"
    }
   },
   "id": "8c90c9c0433192b6",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[0.1003, 0.8953, 0.3099, 0.8571],\n",
      "        [0.6511, 0.8674, 0.5029, 0.2171],\n",
      "        [0.5526, 0.5707, 0.4473, 0.4281],\n",
      "        ...,\n",
      "        [0.5971, 0.9654, 0.6815, 0.2721],\n",
      "        [0.0553, 0.8235, 0.5654, 0.5020],\n",
      "        [0.7317, 0.2869, 0.7150, 0.0820]], requires_grad=True)\n",
      "B\n",
      "Parameter containing:\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], requires_grad=True)\n",
      "Epoch: 1, Loss: 0.0010\n",
      "Epoch: 2, Loss: 0.0012\n",
      "Epoch: 3, Loss: 0.0011\n",
      "Epoch: 4, Loss: 0.0009\n",
      "Epoch: 5, Loss: 0.0007\n",
      "Finished Training!\n"
     ]
    }
   ],
   "source": [
    "class NN_LoRA_layer(torch.nn.Module):\n",
    "    def __init__(self, original_model, in_dim, out_dim, rank=4, alpha=1):\n",
    "        super().__init__()\n",
    "        self.original_model = original_model\n",
    "        self.A = torch.nn.Parameter(torch.rand(in_dim, rank), requires_grad=True)\n",
    "        print(self.A)\n",
    "        self.B = torch.nn.Parameter(torch.zeros(rank, out_dim), requires_grad=True)\n",
    "        print(\"B\")\n",
    "        print(self.B)\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, x):\n",
    "        output1 = self.original_model(x)\n",
    "        # LORA \n",
    "        x = torch.flatten(x)\n",
    "        output2 = self.alpha * (x @ self.A @ self.B)\n",
    "        return output1 + output2\n",
    "\n",
    "\n",
    "# Model creation\n",
    "lora_model = NN_LoRA_layer(original_model= model, in_dim=in_dim, out_dim=10)\n",
    "optimizer = torch.optim.SGD(lora_model.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "# Training\n",
    "for epoch in range(5):\n",
    "    loss = 0\n",
    "    for images, labels in train_data2.dataset:\n",
    "        optimizer.zero_grad()\n",
    "        output = lora_model.forward(images)\n",
    "        loss = criterion(output, torch.tensor(labels))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch: {epoch + 1}, Loss: {loss.item():.4f}')\n",
    "print(\"Finished Training!\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-17T22:13:38.729569500Z",
     "start_time": "2024-08-17T22:13:17.158692900Z"
    }
   },
   "id": "27b73ae682ce773f",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.78%\n"
     ]
    }
   ],
   "source": [
    "# Prediction using created model.\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader2.dataset:\n",
    "        outputs = lora_model.forward(images)\n",
    "        predicted = torch.argmax(outputs)\n",
    "        total += 1\n",
    "        if predicted == labels:\n",
    "            correct += 1\n",
    "    print(f'Accuracy: {(correct / total) * 100}%')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-17T22:13:40.146631700Z",
     "start_time": "2024-08-17T22:13:38.730570Z"
    }
   },
   "id": "eb5cded9d3cebf39",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "OrderedDict([('A',\n              tensor([[0.1003, 0.8953, 0.3099, 0.8571],\n                      [0.6511, 0.8674, 0.5029, 0.2171],\n                      [0.5526, 0.5707, 0.4473, 0.4281],\n                      ...,\n                      [0.5971, 0.9654, 0.6815, 0.2721],\n                      [0.0553, 0.8235, 0.5654, 0.5020],\n                      [0.7317, 0.2869, 0.7150, 0.0820]])),\n             ('B',\n              tensor([[ 0.1827, -0.2141,  0.1311, -0.1663,  0.0314, -0.2191, -0.1150,  0.1282,\n                        0.2670, -0.0259],\n                      [-0.0154,  0.0873, -0.0267, -0.1106, -0.0615,  0.2729,  0.1619,  0.0656,\n                       -0.1395, -0.2341],\n                      [ 0.1395, -0.1523, -0.0575,  0.2883, -0.2756, -0.0160, -0.0550,  0.0310,\n                       -0.1087,  0.2063],\n                      [-0.2355,  0.0183, -0.1001, -0.0234,  0.3345, -0.0789,  0.1689, -0.1382,\n                        0.0313,  0.0230]])),\n             ('original_model.linear.0.weight',\n              tensor([[ 0.0033, -0.0357, -0.0030,  ..., -0.0270, -0.0311, -0.0238],\n                      [ 0.0321, -0.0260,  0.0225,  ...,  0.0202,  0.0092, -0.0216],\n                      [ 0.0037,  0.0052, -0.0058,  ...,  0.0064,  0.0347, -0.0038],\n                      ...,\n                      [-0.0226, -0.0335,  0.0027,  ..., -0.0149,  0.0328, -0.0151],\n                      [ 0.0052, -0.0110, -0.0333,  ...,  0.0108,  0.0294, -0.0327],\n                      [-0.0331, -0.0090,  0.0055,  ...,  0.0213, -0.0107,  0.0040]])),\n             ('original_model.linear.0.bias',\n              tensor([ 7.2809e-02, -1.5484e-01,  1.6819e-01,  1.2447e-01, -1.0037e-01,\n                      -9.8046e-02, -1.5440e-02, -9.0557e-02, -1.0223e-01, -2.6211e-02,\n                       1.7063e-01,  7.5134e-03, -1.1773e-02,  2.0018e-01, -1.1435e-04,\n                       6.1774e-03,  2.4461e-03,  3.3558e-03, -5.3300e-02, -5.1392e-03,\n                       3.1533e-01,  4.7964e-02, -2.3692e-01, -7.0485e-02, -1.3340e-01,\n                       8.4378e-03, -1.6979e-02,  2.6856e-01,  1.4679e-02, -8.3339e-02,\n                       3.1860e-02, -1.0182e-01, -9.4449e-03,  2.8610e-01, -4.6757e-03,\n                       8.6825e-02,  1.4636e-01, -3.2076e-02,  1.7473e-02,  4.4513e-01,\n                       3.6585e-02, -1.2669e-01, -1.1080e-01,  1.6188e-01,  1.4365e-02,\n                       2.4817e-01, -1.4057e-01,  1.1125e-01,  2.5972e-01, -1.2062e-01,\n                       6.1648e-02,  1.6925e-01, -7.2692e-02,  1.7211e-01, -3.0850e-02,\n                      -5.5241e-02, -4.6596e-02, -1.8092e-01, -3.3963e-01, -1.4198e-01,\n                       1.9759e-01, -1.9335e-01,  1.2757e-01, -2.7579e-02, -5.9100e-02,\n                      -1.7772e-01, -5.1468e-03,  8.6605e-02, -9.5679e-02,  2.5514e-02,\n                       2.6728e-02, -1.7106e-03,  4.1906e-02,  2.1679e-01, -5.3184e-03,\n                       1.3782e-01, -2.8981e-02, -1.7497e-02,  6.4558e-02, -1.5781e-01,\n                       3.3125e-01,  7.4184e-02,  5.3076e-03,  4.9255e-03, -2.4555e-02,\n                      -8.5567e-02,  1.0712e-01,  8.9159e-02,  1.7067e-01, -1.1674e-01,\n                      -1.0796e-01, -6.8538e-02, -1.7014e-01, -9.7774e-02,  1.0020e-03,\n                      -1.1678e-02,  4.2995e-03, -1.9828e-01,  3.1675e-02,  4.7768e-02,\n                      -3.9110e-02,  6.3866e-02,  1.5455e-01,  3.0842e-01,  6.1438e-02,\n                       6.9802e-03, -2.5719e-01, -3.1324e-03,  5.1004e-02,  2.2896e-02,\n                      -1.1026e-01, -1.2178e-01,  1.9100e-02,  1.0532e-01,  3.6342e-01,\n                       2.3676e-01,  6.4142e-02,  7.6893e-02,  6.6459e-02, -1.0223e-01,\n                      -1.3843e-02,  1.5636e-02, -2.1197e-01,  1.6637e-02,  1.1909e-01,\n                       2.6302e-02,  8.6516e-02, -2.2851e-02])),\n             ('original_model.linear.2.weight',\n              tensor([[-0.1311,  0.0865, -0.0883,  ..., -0.6896,  0.0154, -0.2262],\n                      [-0.0986, -0.1860,  0.1504,  ...,  0.4199, -0.2991, -0.0232],\n                      [ 0.0076,  0.4133, -0.6364,  ...,  0.2558,  0.1465, -0.3360],\n                      ...,\n                      [-0.1919, -0.1582,  0.2566,  ..., -0.2332, -0.3063, -0.2689],\n                      [ 0.0266,  0.3187,  0.0661,  ...,  0.5547,  0.2124, -0.6399],\n                      [ 0.1338,  0.1437,  0.5277,  ...,  0.0272,  0.2920,  0.2037]])),\n             ('original_model.linear.2.bias',\n              tensor([-0.3482, -0.0754, -0.1047, -0.1559,  0.2177,  0.3243, -0.2668, -0.2297,\n                       0.5357,  0.0200]))])"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_model.state_dict()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-17T22:13:40.170356700Z",
     "start_time": "2024-08-17T22:13:40.148135200Z"
    }
   },
   "id": "9bf638294b3a0cb5",
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
