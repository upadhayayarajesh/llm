{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T22:13:17.109197500Z",
     "start_time": "2024-08-17T22:13:15.509682Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43b5afcfad827a25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T22:13:17.124524600Z",
     "start_time": "2024-08-17T22:13:17.110197500Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\incognito\\AppData\\Local\\Temp\\ipykernel_6552\\697540848.py:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(path))\n"
     ]
    }
   ],
   "source": [
    "# Loading the model\n",
    "class FeedForwardNetwork(torch.nn.Module):\n",
    "    def __init__(self, in_dim, embedding_dim=128, out_dim=10):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(in_dim, embedding_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(embedding_dim, out_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x)\n",
    "        return self.linear(x)\n",
    "    \n",
    "model = FeedForwardNetwork(in_dim=784, out_dim=10, embedding_dim=128)\n",
    "path = \"./model/two_layer_linear_model.pth\"\n",
    "model.load_state_dict(torch.load(path))\n",
    "(w1,b1,w2,b2) = model.parameters()\n",
    "\n",
    "# Freezing weight\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c90c9c0433192b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T22:13:17.158692900Z",
     "start_time": "2024-08-17T22:13:17.124524600Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:01<00:00, 5714039.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 462150.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 4777682.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 1515796.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load  the MNIST dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "full_data = datasets.MNIST(root='./data', transform=transform, download=True)\n",
    "split_percent = int(0.25 * len(full_data))\n",
    "train_data1, test_data1, train_data2, test_data2 = random_split(full_data, [split_percent, split_percent, split_percent,\n",
    "                                                                            split_percent])\n",
    "train_data2 = DataLoader(dataset=train_data2, shuffle=True)\n",
    "test_loader2 = DataLoader(dataset=test_data2, shuffle=True)\n",
    "in_dim = (train_data2.dataset[0][0].size()[1]) ** 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27b73ae682ce773f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T22:13:38.729569500Z",
     "start_time": "2024-08-17T22:13:17.158692900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[0.3193, 0.7511, 0.7246, 0.0439],\n",
      "        [0.5606, 0.7165, 0.4825, 0.4677],\n",
      "        [0.3309, 0.1528, 0.3955, 0.1771],\n",
      "        ...,\n",
      "        [0.6981, 0.6977, 0.3373, 0.5016],\n",
      "        [0.9370, 0.8224, 0.4838, 0.1313],\n",
      "        [0.0512, 0.0374, 0.9726, 0.6047]], requires_grad=True)\n",
      "B\n",
      "Parameter containing:\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], requires_grad=True)\n",
      "Epoch: 1, Loss: 0.0002\n",
      "Epoch: 2, Loss: 0.0002\n",
      "Epoch: 3, Loss: 0.0002\n",
      "Epoch: 4, Loss: 0.0002\n",
      "Epoch: 5, Loss: 0.0002\n",
      "Finished Training!\n"
     ]
    }
   ],
   "source": [
    "class NN_LoRA_layer(torch.nn.Module):\n",
    "    def __init__(self, original_model, in_dim, out_dim, rank=4, alpha=1):\n",
    "        super().__init__()\n",
    "        self.original_model = original_model\n",
    "        self.A = torch.nn.Parameter(torch.rand(in_dim, rank), requires_grad=True)\n",
    "        print(self.A)\n",
    "        self.B = torch.nn.Parameter(torch.zeros(rank, out_dim), requires_grad=True)\n",
    "        print(\"B\")\n",
    "        print(self.B)\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, x):\n",
    "        output1 = self.original_model(x)\n",
    "        # LORA \n",
    "        x = torch.flatten(x)\n",
    "        output2 = self.alpha * (x @ self.A @ self.B)\n",
    "        return output1 + output2\n",
    "\n",
    "\n",
    "# Model creation\n",
    "lora_model = NN_LoRA_layer(original_model= model, in_dim=in_dim, out_dim=10)\n",
    "optimizer = torch.optim.SGD(lora_model.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "# Training\n",
    "for epoch in range(5):\n",
    "    loss = 0\n",
    "    for images, labels in train_data2.dataset:\n",
    "        optimizer.zero_grad()\n",
    "        output = lora_model.forward(images)\n",
    "        loss = criterion(output, torch.tensor(labels))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch: {epoch + 1}, Loss: {loss.item():.4f}')\n",
    "print(\"Finished Training!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb5cded9d3cebf39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T22:13:40.146631700Z",
     "start_time": "2024-08-17T22:13:38.730570Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.56666666666666%\n"
     ]
    }
   ],
   "source": [
    "# Prediction using created model.\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader2.dataset:\n",
    "        outputs = lora_model.forward(images)\n",
    "        predicted = torch.argmax(outputs)\n",
    "        total += 1\n",
    "        if predicted == labels:\n",
    "            correct += 1\n",
    "    print(f'Accuracy: {(correct / total) * 100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bf638294b3a0cb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T22:13:40.170356700Z",
     "start_time": "2024-08-17T22:13:40.148135200Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('A',\n",
       "              tensor([[0.3193, 0.7511, 0.7246, 0.0439],\n",
       "                      [0.5606, 0.7165, 0.4825, 0.4677],\n",
       "                      [0.3309, 0.1528, 0.3955, 0.1771],\n",
       "                      ...,\n",
       "                      [0.6981, 0.6977, 0.3373, 0.5016],\n",
       "                      [0.9370, 0.8224, 0.4838, 0.1313],\n",
       "                      [0.0512, 0.0374, 0.9726, 0.6047]])),\n",
       "             ('B',\n",
       "              tensor([[-0.1666,  0.1460,  0.0210,  0.1407, -0.2974,  0.0495,  0.0820, -0.0860,\n",
       "                       -0.2111,  0.3220],\n",
       "                      [-0.0098,  0.2407, -0.1892, -0.1981,  0.2429, -0.1438,  0.0071,  0.1365,\n",
       "                        0.0014, -0.0876],\n",
       "                      [ 0.1027, -0.2304,  0.1188, -0.0760,  0.2408,  0.1243, -0.0160, -0.1987,\n",
       "                        0.0144, -0.0799],\n",
       "                      [ 0.4395, -0.1162, -0.0628,  0.0967, -0.1426, -0.0964,  0.1148,  0.0774,\n",
       "                       -0.1670, -0.1435]])),\n",
       "             ('original_model.linear.0.weight',\n",
       "              tensor([[ 0.0033, -0.0357, -0.0030,  ..., -0.0270, -0.0311, -0.0238],\n",
       "                      [ 0.0321, -0.0260,  0.0225,  ...,  0.0202,  0.0092, -0.0216],\n",
       "                      [ 0.0037,  0.0052, -0.0058,  ...,  0.0064,  0.0347, -0.0038],\n",
       "                      ...,\n",
       "                      [-0.0226, -0.0335,  0.0027,  ..., -0.0149,  0.0328, -0.0151],\n",
       "                      [ 0.0052, -0.0110, -0.0333,  ...,  0.0108,  0.0294, -0.0327],\n",
       "                      [-0.0331, -0.0090,  0.0055,  ...,  0.0213, -0.0107,  0.0040]])),\n",
       "             ('original_model.linear.0.bias',\n",
       "              tensor([ 7.2809e-02, -1.5484e-01,  1.6819e-01,  1.2447e-01, -1.0037e-01,\n",
       "                      -9.8046e-02, -1.5440e-02, -9.0557e-02, -1.0223e-01, -2.6211e-02,\n",
       "                       1.7063e-01,  7.5134e-03, -1.1773e-02,  2.0018e-01, -1.1435e-04,\n",
       "                       6.1774e-03,  2.4461e-03,  3.3558e-03, -5.3300e-02, -5.1392e-03,\n",
       "                       3.1533e-01,  4.7964e-02, -2.3692e-01, -7.0485e-02, -1.3340e-01,\n",
       "                       8.4378e-03, -1.6979e-02,  2.6856e-01,  1.4679e-02, -8.3339e-02,\n",
       "                       3.1860e-02, -1.0182e-01, -9.4449e-03,  2.8610e-01, -4.6757e-03,\n",
       "                       8.6825e-02,  1.4636e-01, -3.2076e-02,  1.7473e-02,  4.4513e-01,\n",
       "                       3.6585e-02, -1.2669e-01, -1.1080e-01,  1.6188e-01,  1.4365e-02,\n",
       "                       2.4817e-01, -1.4057e-01,  1.1125e-01,  2.5972e-01, -1.2062e-01,\n",
       "                       6.1648e-02,  1.6925e-01, -7.2692e-02,  1.7211e-01, -3.0850e-02,\n",
       "                      -5.5241e-02, -4.6596e-02, -1.8092e-01, -3.3963e-01, -1.4198e-01,\n",
       "                       1.9759e-01, -1.9335e-01,  1.2757e-01, -2.7579e-02, -5.9100e-02,\n",
       "                      -1.7772e-01, -5.1468e-03,  8.6605e-02, -9.5679e-02,  2.5514e-02,\n",
       "                       2.6728e-02, -1.7106e-03,  4.1906e-02,  2.1679e-01, -5.3184e-03,\n",
       "                       1.3782e-01, -2.8981e-02, -1.7497e-02,  6.4558e-02, -1.5781e-01,\n",
       "                       3.3125e-01,  7.4184e-02,  5.3076e-03,  4.9255e-03, -2.4555e-02,\n",
       "                      -8.5567e-02,  1.0712e-01,  8.9159e-02,  1.7067e-01, -1.1674e-01,\n",
       "                      -1.0796e-01, -6.8538e-02, -1.7014e-01, -9.7774e-02,  1.0020e-03,\n",
       "                      -1.1678e-02,  4.2995e-03, -1.9828e-01,  3.1675e-02,  4.7768e-02,\n",
       "                      -3.9110e-02,  6.3866e-02,  1.5455e-01,  3.0842e-01,  6.1438e-02,\n",
       "                       6.9802e-03, -2.5719e-01, -3.1324e-03,  5.1004e-02,  2.2896e-02,\n",
       "                      -1.1026e-01, -1.2178e-01,  1.9100e-02,  1.0532e-01,  3.6342e-01,\n",
       "                       2.3676e-01,  6.4142e-02,  7.6893e-02,  6.6459e-02, -1.0223e-01,\n",
       "                      -1.3843e-02,  1.5636e-02, -2.1197e-01,  1.6637e-02,  1.1909e-01,\n",
       "                       2.6302e-02,  8.6516e-02, -2.2851e-02])),\n",
       "             ('original_model.linear.2.weight',\n",
       "              tensor([[-0.1311,  0.0865, -0.0883,  ..., -0.6896,  0.0154, -0.2262],\n",
       "                      [-0.0986, -0.1860,  0.1504,  ...,  0.4199, -0.2991, -0.0232],\n",
       "                      [ 0.0076,  0.4133, -0.6364,  ...,  0.2558,  0.1465, -0.3360],\n",
       "                      ...,\n",
       "                      [-0.1919, -0.1582,  0.2566,  ..., -0.2332, -0.3063, -0.2689],\n",
       "                      [ 0.0266,  0.3187,  0.0661,  ...,  0.5547,  0.2124, -0.6399],\n",
       "                      [ 0.1338,  0.1437,  0.5277,  ...,  0.0272,  0.2920,  0.2037]])),\n",
       "             ('original_model.linear.2.bias',\n",
       "              tensor([-0.3482, -0.0754, -0.1047, -0.1559,  0.2177,  0.3243, -0.2668, -0.2297,\n",
       "                       0.5357,  0.0200]))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_model.state_dict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
